[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects/project2/index.html",
    "href": "projects/project2/index.html",
    "title": "Project 2",
    "section": "",
    "text": "Coming soon!"
  },
  {
    "objectID": "projects/project1/hw1_blog.html",
    "href": "projects/project1/hw1_blog.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn this study, the researchers mailed out approximately 50,000 fundraising letters to past donors of a nonprofit organization, randomly assigning each individual to one of three experimental treatments. The treatments varied in key design features that aimed to lower the effective “price” of donating. In the control group, recipients received a standard fundraising letter that followed the organization’s typical solicitations—with no mention of matching or challenge grants. For the treatment groups, two alternative letter formats were used: one that incorporated a matching grant offer and another that featured a challenge grant offer. In the matching treatment, an additional paragraph was inserted in the letter to announce that a prominent leadership donor would match every donation dollar—for example, a 1:1 match, meaning that for each dollar the recipient donated, the organization would receive an extra dollar from the donor. The challenge treatment was designed to highlight the effectiveness and urgency of the fundraising effort, sometimes by using higher matching ratios such as 2:1 or 3:1.\nBeyond just the matching ratio, the experiment also varied other elements of the solicitation letter. For instance, the maximum amount available to be matched (e.g., $25,000, $50,000, or $100,000) was randomly assigned, and the letter included different suggested donation amounts based on the donor’s past giving history. This multifaceted randomization allowed the authors to disentangle whether and how explicitly lowering the “price” of a donation—with the promise of additional matching funds—increases both the likelihood that a donor will contribute and the amount they give.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/hw1_blog.html#introduction",
    "href": "projects/project1/hw1_blog.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn this study, the researchers mailed out approximately 50,000 fundraising letters to past donors of a nonprofit organization, randomly assigning each individual to one of three experimental treatments. The treatments varied in key design features that aimed to lower the effective “price” of donating. In the control group, recipients received a standard fundraising letter that followed the organization’s typical solicitations—with no mention of matching or challenge grants. For the treatment groups, two alternative letter formats were used: one that incorporated a matching grant offer and another that featured a challenge grant offer. In the matching treatment, an additional paragraph was inserted in the letter to announce that a prominent leadership donor would match every donation dollar—for example, a 1:1 match, meaning that for each dollar the recipient donated, the organization would receive an extra dollar from the donor. The challenge treatment was designed to highlight the effectiveness and urgency of the fundraising effort, sometimes by using higher matching ratios such as 2:1 or 3:1.\nBeyond just the matching ratio, the experiment also varied other elements of the solicitation letter. For instance, the maximum amount available to be matched (e.g., $25,000, $50,000, or $100,000) was randomly assigned, and the letter included different suggested donation amounts based on the donor’s past giving history. This multifaceted randomization allowed the authors to disentangle whether and how explicitly lowering the “price” of a donation—with the promise of additional matching funds—increases both the likelihood that a donor will contribute and the amount they give.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/hw1_blog.html#data",
    "href": "projects/project1/hw1_blog.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nWe begin by reading the Stata data file (karlan_list_2007.dta) into Python using Pandas. This dataset comes from Karlan and List’s 2007 field experiment and contains 50,000 observations (one for each fundraising letter) and over 50 variables that document experimental assignments, donation outcomes, and donor characteristics. The experimental design includes indicators for whether the letter was a control or a treatment (matching/challenge) along with features such as the match ratio (e.g., 1:1, 2:1, or 3:1) and the match threshold (e.g., $25,000, $50,000, $100,000, or unstated). In addition, the dataset contains variables that measure donor characteristics (e.g. previous donation history, demographic information, and proxy measures for political environment) that allow for an analysis of heterogeneous effects.\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Load the Stata file\ndata = pd.read_stata(\"karlan_list_2007.dta\")\ndata.head()\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\nCode\ndata.describe()\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\nCode\n# Group by treatment and compute average donation and response rate\ngroup_stats = data.groupby(\"treatment\").agg(\n    response_rate=(\"gave\", \"mean\"),\n    avg_donation=(\"gave\", lambda x: data.loc[x.index, \"amount\"].mean())\n)\ngroup_stats.reset_index()\n\n\n\n\n\n\n\n\n\ntreatment\nresponse_rate\navg_donation\n\n\n\n\n0\n0\n0.017858\n0.813268\n\n\n1\n1\n0.022039\n0.966873\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\nThe dataset contains a mixture of experimental design variables (e.g., treatment, control, ratio, size, and various versions of the suggested donation variables) and donor characteristics (e.g., female, couple, and zip code–level demographic information). This rich set of variables supports both a direct replication of the original study’s effects as well as further investigation into heterogeneous treatment responses.\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nWe perform two analyses: T-test Approach and Linear Regression Approach.\n\nT-test Approach\n\n\nCode\nimport scipy.stats as stats\n\n# Drop missing values for the variable mrm2 (months since last donation)\ndata_n = data.dropna(subset=[\"mrm2\"])\n\ntreatment_group = data_n[data_n[\"treatment\"] == 1][\"mrm2\"]\ncontrol_group   = data_n[data_n[\"treatment\"] == 0][\"mrm2\"]\n\nt_stat, p_val = stats.ttest_ind(treatment_group, control_group, equal_var=True)\n\nprint(\"T-test for mrm2:\")\nprint(\"  t-statistic =\", round(t_stat, 4))\nprint(\"  p-value     =\", round(p_val, 4))\n\n\nT-test for mrm2:\n  t-statistic = 0.1195\n  p-value     = 0.9049\n\n\nWe first conduct a two-sample t-test comparing the means of mrm2 between the treatment and control groups using the formula:\n\\[\nt = \\frac{\\bar{x}_1 - \\bar{x}_0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_0^2}{n_0}}}\n\\]\nSince the p-value is much greater than 0.05, we fail to reject the null hypothesis. There is no statistically significant difference between the two groups in terms of months since last donation.\n\n\nLinear Regression Approach\n\n\nCode\nimport statsmodels.formula.api as smf\n\n# Run a linear regression of mrm2 on the treatment indicator.\n# The model: mrm2 = beta0 + beta1 * treatment + error.\nmodel = smf.ols(\"mrm2 ~ treatment\", data=data).fit()\n\nprint(\"Linear Regression Output (mrm2 ~ treatment):\")\nprint(model.summary().tables[1])\n\n\nLinear Regression Output (mrm2 ~ treatment):\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\n\n\nWe then estimate the following regression model:\n\\[\n\\text{mrm2}_i = \\beta_0 + \\beta_1 \\cdot \\text{treatment}_i + \\epsilon_i\n\\]\nThe estimated coefficient for treatment is:\n\ncoef: 0.0137\nstd err: 0.115\nt-stat: 0.119\np-value: 0.905\n95% CI: ([-0.211, 0.238])\n\nThis result matches the t-test output exactly (as expected, since the two methods are equivalent in this context). The coefficient is close to zero and not statistically significant, providing further evidence that the treatment and control groups are balanced on this variable.\nThe purpose of these tests is to assess whether the randomization successfully created equivalent groups on observable characteristics. Since both the t-test and regression show no significant differences in mrm2, we conclude that this variable is balanced across the groups. This kind of table and analysis appears in Table 1 of the original Karlan and List (2007) paper. Including such balance checks is standard in experimental work—it helps ensure that differences in outcomes can be attributed to the treatment and not to confounding factors."
  },
  {
    "objectID": "projects/project1/hw1_blog.html#experimental-results",
    "href": "projects/project1/hw1_blog.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, we analyze whether matched donations lead to an increased response rate—that is, an increased probability that someone donates. In our data, the binary variable gave equals 1 if a donation was made and 0 otherwise.\nBelow is a barplot with two bars: one for the control group and one for the treatment group. Each bar represents the proportion of people in that group who donated.\n\n\nCode\n# Make sure to drop any missing values in the outcome variable (if needed)\ndata_n = data.dropna(subset=[\"gave\"])\n\n# Compute the proportion of individuals who gave (gave==1) by treatment group.\nprop_data = data_n.groupby(\"treatment\")[\"gave\"].mean().reset_index()\nprop_data[\"Group\"] = prop_data[\"treatment\"].map({0: \"Control\", 1: \"Treatment\"})\n\n# Create the barplot using seaborn.\nplt.figure(figsize=(6, 4))\nsns.barplot(x=\"Group\", y=\"gave\", data=prop_data, palette=\"viridis\")\nplt.ylabel(\"Proportion Donated\")\nplt.title(\"Donation Response Rate by Group\")\nplt.ylim(0, 0.3)\nplt.show()\n\n\nC:\\Users\\22344\\AppData\\Local\\Temp\\ipykernel_1044\\256720481.py:10: FutureWarning:\n\n\n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n\n\n\n\n\n\n\n\n\n\nT-test for Donation Response\n\n\nCode\n# Drop rows with missing values in 'gave' (if any)\ndata_n = data.dropna(subset=[\"gave\"])\n\n# Separate the binary outcome for the treatment and control groups.\ntreatment_outcome = data_n[data_n[\"treatment\"] == 1][\"gave\"]\ncontrol_outcome   = data_n[data_n[\"treatment\"] == 0][\"gave\"]\n\n# Conduct an independent-samples t-test assuming equal variances.\nt_stat, p_val = stats.ttest_ind(treatment_outcome, control_outcome, equal_var=True)\nprint(\"T-test for the binary outcome 'gave':\")\nprint(\"  t-statistic =\", round(t_stat, 4))\nprint(\"  p-value     =\", round(p_val, 4))\n\n\nT-test for the binary outcome 'gave':\n  t-statistic = 3.1014\n  p-value     = 0.0019\n\n\nBivariate Linear Regression\n\n\nCode\nmodel_lm = smf.ols(\"gave ~ treatment\", data=data).fit()\nprint(\"Linear Regression Results (dependent variable: gave):\")\nprint(model_lm.summary().tables[1])\n\n\nLinear Regression Results (dependent variable: gave):\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\n\n\nThe t-test result shows a t-statistic of 3.10 and a p-value of 0.0019, which is well below the common threshold of 0.05. This means the observed difference in donation rates is very unlikely to be due to chance. The regression confirms this: the estimated treatment effect (treatment coefficient) is 0.0042, or about a 0.42 percentage point increase in the likelihood of donating for those who received the matching offer. Although this might sound small, it’s a relative increase of over 23% compared to the control group’s base rate of ~1.8% (the intercept).\nThese findings are a powerful demonstration of how framing and perceived impact can affect real-world decisions. Even though the monetary benefit to the donor doesn’t change, simply highlighting that their donation will be matched makes giving feel more impactful or worthwhile. This reflects a broader pattern in behavioral economics: people are more motivated when they believe their actions make a bigger difference People aren’t just giving because they can—they’re giving because the matching offer increases the perceived value of their contribution. This supports the theoretical idea that lowering the “price” of a public good (or increasing its “value”) increases its provision, even in voluntary settings.\nTo assess the effect of being offered a matched donation on the likelihood of donating, we estimate a probit regression where the outcome is a binary variable (gave) indicating whether a donation was made. The key independent variable is the treatment assignment (treatment = 1 if the individual received a letter with a matching grant, 0 otherwise).\n\n\nCode\ndata_n = data.dropna(subset=[\"gave\"])\n\n# Run the probit regression: donate (gave) ~ treatment.\nmodel_probit = smf.probit(\"gave ~ treatment\", data=data_n).fit()\nprint(\"Probit Regression Results (dependent variable: gave):\")\nprint(model_probit.summary())\n\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\nProbit Regression Results (dependent variable: gave):\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Thu, 24 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        00:04:00   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\nThis finding replicates Table 3, Column 1 of Karlan and List (2007), reinforcing the conclusion that even modest changes to how charitable appeals are framed—such as offering to match a donor’s contribution—can have a measurable impact on donor behavior. These results support the broader theory that people are more likely to contribute when they perceive that their donation will go further. From a fundraising strategy perspective, this suggests that matching offers are an effective lever to boost response rates.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nIn this section, we assess whether the size of the matched donation (i.e., the match ratio) has an effect on whether people donate. In our experiment, treatment letters were randomly assigned to include one of three match ratios: 1:1, 2:1, or 3:1. According to the original study, the figures suggest that while a matching offer increases the likelihood of donating relative to a control group, further increases in the match ratio (from 1:1 to 2:1 and from 2:1 to 3:1) do not have additional effects.\n\nT-test by Match Ratio We first restrict our analysis to the treatment group, then calculate the donation rate (mean of gave) for each match ratio, and finally perform t-tests.\n\n\n\nCode\ntreatment_data = data[data[\"treatment\"] == 1].dropna(subset=[\"gave\"])\n\n# Assuming the dataset contains three dummy variables:\n# 'ratio' indicates a 1:1 match, 'ratio2' indicates a 2:1 match,\n# and 'ratio3' indicates a 3:1 match.\n# (In each observation, exactly one of these is equal to 1.)\n\n# Subset donation outcomes for each match ratio.\ngroup_ratio1 = treatment_data[treatment_data[\"ratio\"] == 1][\"gave\"]\ngroup_ratio2 = treatment_data[treatment_data[\"ratio2\"] == 1][\"gave\"]\ngroup_ratio3 = treatment_data[treatment_data[\"ratio3\"] == 1][\"gave\"]\n\n# T-test: Compare 1:1 vs. 2:1\nt_stat_1_2, p_val_1_2 = stats.ttest_ind(group_ratio1, group_ratio2, equal_var=True)\nprint(\"T-test for 1:1 vs 2:1 match rates:\")\nprint(\"  t-statistic =\", round(t_stat_1_2, 4))\nprint(\"  p-value     =\", round(p_val_1_2, 4))\n\n# T-test: Compare 2:1 vs. 3:1\nt_stat_2_3, p_val_2_3 = stats.ttest_ind(group_ratio2, group_ratio3, equal_var=True)\nprint(\"\\nT-test for 2:1 vs 3:1 match rates:\")\nprint(\"  t-statistic =\", round(t_stat_2_3, 4))\nprint(\"  p-value     =\", round(p_val_2_3, 4))\n\n\nT-test for 1:1 vs 2:1 match rates:\n  t-statistic = -0.965\n  p-value     = 0.3345\n\nT-test for 2:1 vs 3:1 match rates:\n  t-statistic = -0.0501\n  p-value     = 0.96\n\n\n\nRegression Analysis by Match Ratio We now create a variable ratio1 (which is identical to ratio) for clarity, and then regress gave on the match ratio dummies without an intercept.\n\n\n\nCode\ntreatment_data = treatment_data.copy()\ntreatment_data[\"ratio1\"] = treatment_data[\"ratio\"]\n\n# Run the regression without an intercept to estimate group means directly.\nmodel_match = smf.ols(\"gave ~ ratio1 + ratio2 + ratio3 - 1\", data=treatment_data).fit()\nprint(\"Regression Results (no intercept):\")\nprint(model_match.summary().tables[1])\n\n\nRegression Results (no intercept):\n===================================================================================\n                      coef    std err          t      P&gt;|t|      [0.025      0.975]\n-----------------------------------------------------------------------------------\nratio1[Control]          0          0        nan        nan           0           0\nratio1[1]           0.0207      0.001     14.912      0.000       0.018       0.023\nratio1[2]       -4.365e+09   3.12e+10     -0.140      0.889   -6.55e+10    5.67e+10\nratio1[3]       -1.274e+10    9.1e+10     -0.140      0.889   -1.91e+11    1.66e+11\nratio2           4.365e+09   3.12e+10      0.140      0.889   -5.67e+10    6.55e+10\nratio3           1.274e+10    9.1e+10      0.140      0.889   -1.66e+11    1.91e+11\n===================================================================================\n\n\nC:\\Users\\22344\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\regression\\linear_model.py:1966: RuntimeWarning:\n\ndivide by zero encountered in scalar divide\n\n\n\n\nCalculating and Comparing Differences\n\n\n\nCode\ntreatment_data = treatment_data.copy()\ntreatment_data[\"ratio1\"] = pd.to_numeric(treatment_data[\"ratio\"], errors='coerce')\ntreatment_data[\"ratio2\"] = pd.to_numeric(treatment_data[\"ratio2\"], errors='coerce')\ntreatment_data[\"ratio3\"] = pd.to_numeric(treatment_data[\"ratio3\"], errors='coerce')\n\n# Run the regression without an intercept:\nmodel_match = smf.ols(\"gave ~ ratio1 + ratio2 + ratio3 - 1\", data=treatment_data).fit()\n\n# Check what parameter names are in the fitted model:\nprint(\"Model Parameters:\", model_match.params.index.tolist())\n\n# Now extract the coefficients:\ncoeffs = model_match.params\nmu_ratio1 = coeffs[\"ratio1\"]\nmu_ratio2 = coeffs[\"ratio2\"]\nmu_ratio3 = coeffs[\"ratio3\"]\n\ndiff_2_vs_1_coef = mu_ratio2 - mu_ratio1\ndiff_3_vs_2_coef = mu_ratio3 - mu_ratio2\n\nprint(\"Fitted Coefficient Differences:\")\nprint(\"  Difference between 2:1 and 1:1 (regression):\", round(diff_2_vs_1_coef, 4))\nprint(\"  Difference between 3:1 and 2:1 (regression):\", round(diff_3_vs_2_coef, 4))\n\n\nModel Parameters: ['ratio1', 'ratio2', 'ratio3']\nFitted Coefficient Differences:\n  Difference between 2:1 and 1:1 (regression): -0.0396\n  Difference between 3:1 and 2:1 (regression): -0.0206\n\n\nBoth our t‑tests and regression analyses converge on the same conclusion: although the introduction of a matching donation offer (versus no match) increases the probability that an individual donates, increasing the match ratio beyond 1:1 (i.e., comparing 1:1 to 2:1 and 2:1 to 3:1) does not further increase the response rate in a statistically significant way. In plain language, donors seem to respond to the existence of a matching offer rather than the exact size of the match. This finding supports the observation mentioned by the authors on page 8 of the Karlan and List paper that “figures suggest” no additional effect of increasing the match ratio beyond 1:1.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nFull Sample Analysis: We run a t‑test and bivariate linear regression of the donation amount (variable amount) on treatment status, using all observations. Since many people did not donate (i.e. their donation amount is zero), this analysis mixes two effects:\n\n\nThe increased likelihood of donating, and\nThe actual amount given among donors.\n\n\n\nCode\ndata_n = data.dropna(subset=[\"amount\"])\n\n# T-test comparing donation amounts between treatment and control groups\ntreatment_amount = data_n[data_n[\"treatment\"] == 1][\"amount\"]\ncontrol_amount   = data_n[data_n[\"treatment\"] == 0][\"amount\"]\n\nt_stat_full, p_val_full = stats.ttest_ind(treatment_amount, control_amount, equal_var=True)\nprint(\"Full Sample T-test for donation amount:\")\nprint(\"  t-statistic =\", round(t_stat_full, 4))\nprint(\"  p-value =\", round(p_val_full, 4))\n\n# Bivariate linear regression using the full sample.\nmodel_full = smf.ols(\"amount ~ treatment\", data=data_n).fit()\nprint(\"\\nFull Sample Linear Regression Results (amount ~ treatment):\")\nprint(model_full.summary().tables[1])\n\n\nFull Sample T-test for donation amount:\n  t-statistic = 1.8605\n  p-value = 0.0628\n\nFull Sample Linear Regression Results (amount ~ treatment):\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\n\n\nThe t‑test produced a t‑statistic of approximately 1.861 with a p‑value of 0.0628. This result is marginally non‑significant by the conventional 0.05 threshold, suggesting that—when considering the entire sample—the average donation in the treatment group is somewhat higher than in the control group, but the evidence is not strong enough to conclusively rule out that this difference might be due to chance. The estimated intercept was 0.8133, and the treatment coefficient was 0.1536 with a corresponding t‑statistic of 1.861 and a p‑value of 0.063. These results are consistent with the t‑test.\nThere is an increase in the overall donation amount when a matching donation offer is included. However, much of this overall effect is likely driven by an increase in the probability of donating rather than by a substantially higher donation amount among those who do give. That is, while the matching offer appears to encourage more people to donate, it does not necessarily lead existing donors to give much more money.\n\n\nCode\ndata_n = data.dropna(subset=[\"amount\"])\n\ndonors = data[data[\"amount\"] &gt; 0]\n\n# Conduct a t-test comparing donation amounts among donors \n# between treatment and control groups.\ntreatment_amount_cond = donors[donors[\"treatment\"] == 1][\"amount\"]\ncontrol_amount_cond   = donors[donors[\"treatment\"] == 0][\"amount\"]\n\nt_stat_cond, p_val_cond = stats.ttest_ind(treatment_amount_cond, control_amount_cond, equal_var=True)\nprint(\"Conditional T-test for donation amount (donors only):\")\nprint(\"  t-statistic =\", round(t_stat_cond, 4))\nprint(\"  p-value =\", round(p_val_cond, 4))\n\n# Run a bivariate linear regression of donation amount on treatment among donors.\nmodel_cond = smf.ols(\"amount ~ treatment\", data=donors).fit()\nprint(\"\\nConditional Linear Regression Results (amount ~ treatment) among donors:\")\nprint(model_cond.summary().tables[1])\n\n\nConditional T-test for donation amount (donors only):\n  t-statistic = -0.5808\n  p-value = 0.5615\n\nConditional Linear Regression Results (amount ~ treatment) among donors:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\n\n\nThe t-test indicates that the average donation amount among donors does not differ significantly between the treatment and control groups. The intercept is estimated at 45.54 representing the average donation amount among control group donors. The treatment coefficient is estimated at -1.67 with a standard error of 2.87 (t = -0.581, p = 0.561). This coefficient indicates that, among donors, those in the treatment group donate on average about $1.67 less than those in the control group. However, the difference is not statistically significant.\nWhen we restrict the analysis to individuals who donate, the matching treatment does not appear to significantly affect how much they donate. Although the unconditional analysis (which includes both donors and non-donors) shows that the treatment increases the overall probability of donating, the conditional analysis suggests that, among those who choose to donate, the donation size remains largely unchanged. In summary, these results suggest that the matching offer primarily works by encouraging more people to donate; it does not have a significant effect on increasing the average donation size among those who already decide to give.\n\n\nCode\ndata_n = data.dropna(subset=[\"amount\"])\n\n# Restrict analysis to people who donated (amount &gt; 0)\ndonors = data_n[data[\"amount\"] &gt; 0]\n\n# Separate the donation amounts by treatment group\ntreatment_donors = donors[donors[\"treatment\"] == 1][\"amount\"]\ncontrol_donors   = donors[donors[\"treatment\"] == 0][\"amount\"]\n\n# Calculate the mean donation amount for each group\nmean_treatment = treatment_donors.mean()\nmean_control   = control_donors.mean()\n\n# Set up the plotting area\nplt.figure(figsize=(12, 5))\n\n# Plot histogram for the Control group\nplt.subplot(1, 2, 1)\nsns.histplot(control_donors, bins=30, kde=False, color=\"lightblue\")\nplt.axvline(mean_control, color=\"red\", linestyle=\"dashed\", linewidth=2)\nplt.title(\"Control Group: Donation Amounts (Donors Only)\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.text(mean_control, plt.ylim()[1]*0.8, f\"Mean = {mean_control:.2f}\", color=\"red\", ha=\"center\")\n\n# Plot histogram for the Treatment group\nplt.subplot(1, 2, 2)\nsns.histplot(treatment_donors, bins=30, kde=False, color=\"lightgreen\")\nplt.axvline(mean_treatment, color=\"red\", linestyle=\"dashed\", linewidth=2)\nplt.title(\"Treatment Group: Donation Amounts (Donors Only)\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.text(mean_treatment, plt.ylim()[1]*0.8, f\"Mean = {mean_treatment:.2f}\", color=\"red\", ha=\"center\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/project1/hw1_blog.html#simulation-experiment",
    "href": "projects/project1/hw1_blog.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nTo demonstrate the Law of Large Numbers, we simulate a large number of individual draws from two Bernoulli distributions: Control group: p=0.018 Treatment group: p=0.022\n\n\nCode\nimport numpy as np\n\nnp.random.seed(1234)\n\n# Parameters for Bernoulli distributions\np_control = 0.018\np_treatment = 0.022\n\n# Simulate 100,000 draws from the control distribution\ncontrol_full = np.random.binomial(1, p_control, size=100000)\n\n# Randomly select 10,000 draws from the control draws\ncontrol_sample = np.random.choice(control_full, size=10000, replace=False)\n\n# Simulate 10,000 draws from the treatment distribution\ntreatment_sample = np.random.binomial(1, p_treatment, size=10000)\n\n# Calculate the vector of differences (treatment - control) for each pair\ndifferences = treatment_sample - control_sample\n\n# Compute the cumulative average of these differences\ncumulative_avg = np.cumsum(differences) / np.arange(1, 10000 + 1)\n\n# Plot the cumulative average\nplt.figure(figsize=(10,6))\nplt.plot(cumulative_avg, label=\"Cumulative Average of Differences\")\nplt.axhline(y=p_treatment - p_control, color='red', linestyle='--', label=\"True Difference (0.004)\")\nplt.xlabel(\"Number of Observations\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.title(\"Law of Large Numbers: Convergence of the Cumulative Average\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\nBelow, we produce histograms of the sample means for both groups and overlay the appropriate Normal density.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set seed for reproducibility\nnp.random.seed(123)\n\n# Define parameters for the Bernoulli distributions\np_control = 0.018\np_treatment = 0.022\nreps = 1000  # number of experiments (repetitions)\nsample_sizes = [50, 200, 500, 1000]\n\n# Dictionary to store the average difference for each sample size\ndiff_results = {}\n\nfor n in sample_sizes:\n    diffs = []\n    for i in range(reps):\n        # Draw n observations for control and treatment groups\n        control_sample = np.random.binomial(1, p_control, size=n)\n        treatment_sample = np.random.binomial(1, p_treatment, size=n)\n        diff = np.mean(treatment_sample) - np.mean(control_sample)\n        diffs.append(diff)\n    diff_results[n] = np.array(diffs)\n\n# Plot 4 histograms in a 2x2 grid\nfig, axs = plt.subplots(2, 2, figsize=(12, 10))\naxs = axs.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    sns.histplot(diff_results[n], bins=30, stat=\"density\", color=\"lightblue\", ax=axs[i])\n    # Overlay a vertical dashed red line at the true difference (0.004)\n    axs[i].axvline(p_treatment - p_control, color=\"red\", linestyle=\"--\", linewidth=2, label=\"True Difference (0.004)\")\n    axs[i].set_title(f\"Sample Size = {n}\")\n    axs[i].set_xlabel(\"Average Difference (Treatment - Control)\")\n    axs[i].set_ylabel(\"Density\")\n    axs[i].legend()\n\nplt.suptitle(\"Central Limit Theorem: Distribution of Average Differences\", fontsize=16)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yuxing Liu",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nYuxing Liu\n\n\nApr 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nProject 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  }
]